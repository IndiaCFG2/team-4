{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This module returns total positive sentiments, total negative sentiments and the summary points\n",
    "'''\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"feedback_dataset_EIP.xlsx\"\n",
    "POS_OFFSET = 0.1\n",
    "ORIGIN = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback_df():\n",
    "    '''\n",
    "    convert feedback list to df and return \n",
    "    '''\n",
    "    return pd.read_excel(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_regional_languages(feedback_df):\n",
    "    '''\n",
    "    detects and translates any other language to english\n",
    "    '''\n",
    "    translator = Translator()\n",
    "    feedback_df['responseText'] = [translator.translate(x).text for x in feedback_df['responseText']]\n",
    "    return feedback_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_count(feedback_df):\n",
    "    '''\n",
    "    returns total pos and neg count \n",
    "    '''\n",
    "    total_pos = feedback_df[feedback_df['compound']>POS_OFFSET].shape[0]\n",
    "    total_neg = feedback_df[feedback_df['compound']<ORIGIN].shape[0]\n",
    "    total_neu = feedback_df.shape[0] - total_pos - total_neg\n",
    "    return total_pos, total_neg, total_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_votes_metric(feedback_df):\n",
    "    '''\n",
    "    add metric votes:-\n",
    "    votes = upVoteCount - downVoteCount + templatesCount\n",
    "    drop unnecessary cols and sort by values\n",
    "    '''\n",
    "    feedback_df['votes'] = feedback_df['upVoteCount'] - feedback_df['downVoteCount'] + feedback_df['templatesCount']\n",
    "    feedback_df = feedback_df.drop(['upVoteCount','downVoteCount','templatesCount'], 1)\n",
    "    feedback_df.sort_values(by=\"votes\", ascending=False)\n",
    "    return feedback_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_nltk(feedback, sentiment_type=\"compound\"):\n",
    "    '''\n",
    "    Returns sentiment of feedback using NLTK Vader\n",
    "    '''\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(feedback)\n",
    "    # returning NLTK vader compound score\n",
    "    return ss[sentiment_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores(feedback_df):\n",
    "    '''\n",
    "    Populates feedback_df with sentiment scores\n",
    "    '''\n",
    "    \n",
    "    for sentiment_type in ['compound', 'neg', 'pos', 'neu']:\n",
    "        feedback_df[sentiment_type] = [get_sentiment_nltk(x, sentiment_type) for x in feedback_df['responseText']]\n",
    "        \n",
    "    return feedback_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(feedback_df):\n",
    "    '''\n",
    "    [For testing purpose] return a subset of top 3 responses\n",
    "    '''\n",
    "    response_text = feedback_df['responseText'][0] + feedback_df['responseText'][1] + feedback_df['responseText'][2]\n",
    "    \n",
    "    lines_list = tokenize.sent_tokenize(response_text)\n",
    "    line_df = []\n",
    "    for line in lines_list:\n",
    "        row = []\n",
    "        row.append(line)\n",
    "        row.append(get_sentiment_nltk(line))\n",
    "        line_df.append(row)\n",
    "    df = pd.DataFrame(line_df)\n",
    "    df = df.sort_values(by=1)\n",
    "    df = df.head(6)\n",
    "\n",
    "    return df[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''\n",
    "    main\n",
    "    '''\n",
    "    feedback_df = get_feedback_df()\n",
    "    feedback_df = translate_regional_languages(feedback_df)\n",
    "    feedback_df = get_sentiment_scores(feedback_df)\n",
    "    \n",
    "    total_pos, total_neg, total_neu = get_total_count(feedback_df)\n",
    "    \n",
    "    feedback_df = add_votes_metric(feedback_df)\n",
    "    \n",
    "    summary = get_summary(feedback_df)\n",
    "    \n",
    "    print(total_pos)\n",
    "    print(total_neg)\n",
    "    print(total_neu)\n",
    "    print(summary)\n",
    "    print(feedback_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "79\n",
      "1\n",
      "[\"We as a nation lack a cohesive public consultation space and hence most such consultations proceed with paltry inputs after they've been suspended in the void for a few days.\", 'Officials have figured out a way to avoid this situation for sometime â€“ they issue work orders to cut trees in bunches of 49 or lesser.', 'Compliance reports are reduced rather than annual - leading to all the more losses and less need for checkups!', 'One of the major problems with this report is the categorization of the project.', 'Marginal communities that depend on land for all their needs may technically lose it without consulting them for strategic projects.', 'After this, the partner issues of Fight arise.']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
